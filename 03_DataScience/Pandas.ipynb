{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Data Manipulation with Pandas\n",
    "\n",
    "**DataFrames and Series (Advanced Indexing)**\n",
    "\n",
    "*   **`.loc` and `.iloc`:**\n",
    "    *   `.loc`:  Label-based indexing (select rows and columns by their labels).\n",
    "    *   `.iloc`:  Integer-based indexing (select rows and columns by their integer positions).\n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Create a DataFrame\n",
    "    data = {'col1': [1, 2, 3, 4],\n",
    "            'col2': [5, 6, 7, 8],\n",
    "            'col3': [9, 10, 11, 12]}\n",
    "    df = pd.DataFrame(data, index=['A', 'B', 'C', 'D'])\n",
    "\n",
    "    # .loc examples\n",
    "    print(df.loc['A'])        # Row with label 'A'\n",
    "    print(df.loc[['A', 'C']]) # Rows with labels 'A' and 'C'\n",
    "    print(df.loc['B', 'col2']) # Value at row 'B', column 'col2'\n",
    "    print(df.loc['A':'C', 'col1':'col2']) # Slicing with labels\n",
    "\n",
    "    # .iloc examples\n",
    "    print(df.iloc[0])        # First row (index 0)\n",
    "    print(df.iloc[[0, 2]])   # First and third rows\n",
    "    print(df.iloc[1, 1])     # Value at row 1, column 1\n",
    "    print(df.iloc[0:3, 0:2]) # Slicing with integer positions\n",
    "    ```\n",
    "\n",
    "*   **Boolean Indexing:**  Select rows based on a condition.\n",
    "\n",
    "    ```python\n",
    "    print(df[df['col1'] > 2])  # Rows where 'col1' is greater than 2\n",
    "    print(df[(df['col2'] >= 6) & (df['col3'] < 12)]) # Multiple conditions\n",
    "    ```\n",
    "\n",
    "*   **Multi-Indexing (Hierarchical Indexing):**  Create DataFrames with multiple levels of indices.\n",
    "\n",
    "    ```python\n",
    "    index = pd.MultiIndex.from_tuples([('Group1', 'A'), ('Group1', 'B'),\n",
    "                                     ('Group2', 'A'), ('Group2', 'B')],\n",
    "                                    names=['Group', 'Letter'])\n",
    "    data = {'col1': [1, 2, 3, 4], 'col2': [5, 6, 7, 8]}\n",
    "    df_multi = pd.DataFrame(data, index=index)\n",
    "    print(df_multi)\n",
    "\n",
    "    # Accessing data with multi-index\n",
    "    print(df_multi.loc['Group1'])\n",
    "    print(df_multi.loc[('Group1', 'B')]) # Access a specific row\n",
    "    print(df_multi.loc['Group1', 'col1']) #Select a column for a specific group.\n",
    "    print(df_multi.xs('A', level='Letter')) # Cross-section: all rows with 'Letter' = 'A'\n",
    "    ```\n",
    "\n",
    "**Data Cleaning and Transformation**\n",
    "\n",
    "*   **Handling Missing Data (NaN values):**\n",
    "\n",
    "    ```python\n",
    "    df = pd.DataFrame({'col1': [1, np.nan, 3, 4],\n",
    "                      'col2': [5, 6, np.nan, 8]})\n",
    "\n",
    "    # Check for missing values\n",
    "    print(df.isnull())\n",
    "    print(df.isna()) # Same as isnull()\n",
    "    print(df.isnull().sum())  # Count missing values per column\n",
    "\n",
    "    # Drop rows or columns with missing values\n",
    "    print(df.dropna())  # Drop rows with any NaN\n",
    "    print(df.dropna(axis=1))  # Drop columns with any NaN\n",
    "    print(df.dropna(thresh=2))  # Drop rows with fewer than 2 non-NaN values\n",
    "\n",
    "    # Fill missing values\n",
    "    print(df.fillna(0))  # Fill with 0\n",
    "    print(df.fillna(method='ffill'))  # Forward fill (propagate last valid observation)\n",
    "    print(df.fillna(method='bfill'))  # Backward fill\n",
    "    print(df.fillna(df.mean()))  # Fill with column means\n",
    "    ```\n",
    "\n",
    "*   **Data Type Conversions:**\n",
    "\n",
    "    ```python\n",
    "    df = pd.DataFrame({'col1': ['1', '2', '3'], 'col2': [1.1, 2.2, 3.3]})\n",
    "\n",
    "    # Convert to integer\n",
    "    df['col1'] = df['col1'].astype(int)\n",
    "\n",
    "    # Convert to float\n",
    "    # df['col1'] = df['col1'].astype(float) # This will raise an error if the column cannot be converted to float\n",
    "\n",
    "    # Convert to string\n",
    "    df['col2'] = df['col2'].astype(str)\n",
    "\n",
    "    # Convert to datetime\n",
    "    df['date'] = pd.to_datetime(['2023-10-26', '2023-10-27', '2023-10-28'])\n",
    "    print(df.dtypes)\n",
    "    ```\n",
    "\n",
    "*   **String Manipulation:**\n",
    "\n",
    "    ```python\n",
    "    df = pd.DataFrame({'text': ['hello world', 'Python Pandas', 'data science']})\n",
    "\n",
    "    # String methods (vectorized)\n",
    "    print(df['text'].str.upper())\n",
    "    print(df['text'].str.lower())\n",
    "    print(df['text'].str.contains('Python'))\n",
    "    print(df['text'].str.split())\n",
    "    print(df['text'].str.replace(' ', '_'))\n",
    "    ```\n",
    "\n",
    "*   **Applying Custom Functions:**\n",
    "\n",
    "    ```python\n",
    "    # Using apply (row-wise or column-wise)\n",
    "    def my_function(row):\n",
    "        return row['col1'] * 2 + row['col2']\n",
    "\n",
    "    df = pd.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})\n",
    "    df['new_col'] = df.apply(my_function, axis=1)  # Apply row-wise\n",
    "    print(df)\n",
    "\n",
    "    # Using applymap (element-wise)\n",
    "    df = pd.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})\n",
    "    df_squared = df.applymap(lambda x: x**2)\n",
    "    print(df_squared)\n",
    "    ```\n",
    "\n",
    "**Grouping and Aggregation**\n",
    "\n",
    "*   **`groupby` Operations:**\n",
    "\n",
    "    ```python\n",
    "    df = pd.DataFrame({'group': ['A', 'B', 'A', 'B', 'C'],\n",
    "                       'value': [1, 2, 3, 4, 5]})\n",
    "\n",
    "    # Group by a single column\n",
    "    grouped = df.groupby('group')\n",
    "\n",
    "    # Calculate the mean of each group\n",
    "    print(grouped.mean())\n",
    "\n",
    "    # Calculate multiple aggregations\n",
    "    print(grouped.agg({'value': ['sum', 'mean', 'max']}))\n",
    "\n",
    "    # Iterate over groups\n",
    "    for name, group_df in grouped:\n",
    "        print(f\"Group: {name}\")\n",
    "        print(group_df)\n",
    "    ```\n",
    "\n",
    "*   **Transformations:**  Apply a function to each group and return a DataFrame with the same index as the original.\n",
    "\n",
    "    ```python\n",
    "    # Calculate the z-score within each group\n",
    "    df = pd.DataFrame({'group': ['A', 'A', 'B', 'B'], 'value': [1, 2, 3, 4]})\n",
    "    zscore = lambda x: (x - x.mean()) / x.std()\n",
    "    df['zscore'] = df.groupby('group')['value'].transform(zscore)\n",
    "    print(df)\n",
    "    ```\n",
    "\n",
    "*   **Filtering:**  Select groups based on a condition.\n",
    "\n",
    "    ```python\n",
    "    # Keep only groups with a mean greater than 2\n",
    "    filtered_df = df.groupby('group').filter(lambda x: x['value'].mean() > 2)\n",
    "    print(filtered_df)\n",
    "    ```\n",
    "\n",
    "**Merging, Joining, and Concatenating**\n",
    "\n",
    "*   **`pd.concat`:**  Concatenate DataFrames along rows or columns.\n",
    "\n",
    "    ```python\n",
    "    df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "    df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "\n",
    "    # Concatenate along rows (axis=0, default)\n",
    "    print(pd.concat([df1, df2]))\n",
    "\n",
    "    # Concatenate along columns (axis=1)\n",
    "    print(pd.concat([df1, df2], axis=1))\n",
    "\n",
    "    # Handle different indices\n",
    "    df3 = pd.DataFrame({'A': [9, 10]}, index=[2,3])\n",
    "    print(pd.concat([df1, df3])) # Will fill missing values with NaN\n",
    "    print(pd.concat([df1, df3], join='inner')) #Keep only shared columns\n",
    "\n",
    "    ```\n",
    "\n",
    "*   **`pd.merge`:**  Join DataFrames based on common columns (like SQL joins).\n",
    "\n",
    "    ```python\n",
    "    df1 = pd.DataFrame({'key': ['A', 'B', 'C'], 'value1': [1, 2, 3]})\n",
    "    df2 = pd.DataFrame({'key': ['B', 'C', 'D'], 'value2': [4, 5, 6]})\n",
    "\n",
    "    # Inner join (default)\n",
    "    print(pd.merge(df1, df2, on='key'))\n",
    "\n",
    "    # Left join\n",
    "    print(pd.merge(df1, df2, on='key', how='left'))\n",
    "\n",
    "    # Right join\n",
    "    print(pd.merge(df1, df2, on='key', how='right'))\n",
    "\n",
    "    # Outer join\n",
    "    print(pd.merge(df1, df2, on='key', how='outer'))\n",
    "\n",
    "    # Joining on different column names\n",
    "    df3 = pd.DataFrame({'key1': ['A', 'B', 'C'], 'value1': [1, 2, 3]})\n",
    "    df4 = pd.DataFrame({'key2': ['B', 'C', 'D'], 'value2': [4, 5, 6]})\n",
    "    print(pd.merge(df3, df4, left_on='key1', right_on='key2'))\n",
    "\n",
    "    # Joining on index\n",
    "    print(pd.merge(df1, df2, left_index=True, right_index=True, suffixes=('_left', '_right'))) # Example with index and different columns\n",
    "    ```\n",
    "\n",
    "* **`.join`**\n",
    "    ```python\n",
    "    # Simplified version of merge, primarily for joining on index.\n",
    "    left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                      'B': ['B0', 'B1', 'B2']},\n",
    "                     index=['K0', 'K1', 'K2'])\n",
    "    right = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n",
    "                        'D': ['D0', 'D2', 'D3']},\n",
    "                       index=['K0', 'K2', 'K3'])\n",
    "    print(left.join(right)) # left join by default\n",
    "    print(left.join(right, how='outer')) # outer join\n",
    "    ```\n",
    "\n",
    "**Time Series Data**\n",
    "\n",
    "*   **Working with Dates and Times:**\n",
    "\n",
    "    ```python\n",
    "    # Create a DatetimeIndex\n",
    "    dates = pd.to_datetime(['2023-10-26', '2023-10-27', '2023-10-28'])\n",
    "    df = pd.DataFrame({'value': [1, 2, 3]}, index=dates)\n",
    "\n",
    "    # Access components of dates\n",
    "    print(df.index.year)\n",
    "    print(df.index.month)\n",
    "    print(df.index.day)\n",
    "    print(df.index.dayofweek)\n",
    "\n",
    "    # Create a date range\n",
    "    date_range = pd.date_range(start='2023-01-01', end='2023-01-10', freq='D') # Daily frequency\n",
    "    print(date_range)\n",
    "\n",
    "    # Time deltas\n",
    "    print(pd.Timedelta(days=1))\n",
    "    print(df.index + pd.Timedelta(days=2))\n",
    "\n",
    "    ```\n",
    "\n",
    "*   **Resampling:**  Change the frequency of a time series.\n",
    "\n",
    "    ```python\n",
    "    # Create a time series with hourly data\n",
    "    rng = pd.date_range('2023-01-01', periods=24, freq='H')\n",
    "    ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "\n",
    "    # Resample to daily frequency, taking the mean\n",
    "    print(ts.resample('D').mean())\n",
    "\n",
    "    # Resample to 3-hour frequency, forward filling missing values\n",
    "    print(ts.resample('3H').ffill())\n",
    "    ```\n",
    "\n",
    "*   **Shifting:**  Move data forward or backward in time.\n",
    "\n",
    "    ```python\n",
    "    # Shift the data by 1 period forward\n",
    "    print(ts.shift(1))\n",
    "\n",
    "    # Shift the data by 2 periods backward\n",
    "    print(ts.shift(-2))\n",
    "    ```\n",
    "\n",
    "*   **Window Functions:**  Perform calculations over a sliding window of data.\n",
    "\n",
    "    ```python\n",
    "    # Calculate a 3-period rolling mean\n",
    "    print(ts.rolling(window=3).mean())\n",
    "\n",
    "    # Calculate a 3-period rolling sum\n",
    "    print(ts.rolling(window=3).sum())\n",
    "\n",
    "    # Expanding window (cumulative)\n",
    "    print(ts.expanding().mean())\n",
    "    ```\n",
    "\n",
    "**Pivot Tables and Cross-Tabulations**\n",
    "\n",
    "*   **`pivot_table`:**  Reshape data from \"long\" to \"wide\" format.\n",
    "\n",
    "    ```python\n",
    "    df = pd.DataFrame({'A': ['one', 'one', 'two', 'three'] * 3,\n",
    "                       'B': ['A', 'B', 'C'] * 4,\n",
    "                       'C': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
    "                       'D': np.random.randn(12),\n",
    "                       'E': np.random.randn(12)})\n",
    "\n",
    "    # Create a pivot table\n",
    "    pivot = pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'], aggfunc=np.sum)\n",
    "    print(pivot)\n",
    "    ```\n",
    "\n",
    "*   **`crosstab`:**  Compute a simple cross-tabulation of two (or more) factors.\n",
    "\n",
    "    ```python\n",
    "    # Create a cross-tabulation\n",
    "    cross_tab = pd.crosstab(df['A'], df['C'])\n",
    "    print(cross_tab)\n",
    "    ```\n",
    "\n",
    "**Performance Optimization**\n",
    "\n",
    "*   **Vectorized Operations:**  Use Pandas' built-in vectorized operations (string methods, arithmetic operations) instead of loops whenever possible.  This is *much* faster.\n",
    "\n",
    "*   **`apply` Efficiently:**\n",
    "    *   Use `apply` with built-in NumPy functions when possible.\n",
    "    *   For custom functions, ensure they are optimized (e.g., use NumPy operations inside the function).\n",
    "    *   Consider using `numba` to compile your custom functions for even greater speed.\n",
    "\n",
    "*   **Avoid `.iterrows()` and `.itertuples()` (Generally):**  These methods iterate over rows, which is slow.  Use vectorized operations or `apply` instead.  If you *must* iterate, `.itertuples()` is generally faster than `.iterrows()`.\n",
    "\n",
    "* **Data types**: ensure to use appropriate data types.\n",
    "\n",
    "*   **Example:**\n",
    "\n",
    "    ```python\n",
    "    import time\n",
    "    df = pd.DataFrame({'col1': np.random.rand(100000),\n",
    "                      'col2': np.random.rand(100000)})\n",
    "\n",
    "    # Slow: Iterating\n",
    "    def slow_func(df):\n",
    "        total = 0\n",
    "        for index, row in df.iterrows():\n",
    "            total += row['col1'] * row['col2']\n",
    "        return total\n",
    "\n",
    "    start_time = time.time()\n",
    "    slow_func(df)\n",
    "    end_time = time.time()\n",
    "    print(f\"Iterrows time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "    # Fast: Vectorized\n",
    "    def fast_func(df):\n",
    "        return (df['col1'] * df['col2']).sum()\n",
    "\n",
    "    start_time = time.time()\n",
    "    fast_func(df)\n",
    "    end_time = time.time()\n",
    "    print(f\"Vectorized time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "    # Apply (better than iterrows, but still slower than vectorization)\n",
    "    def apply_func(row):\n",
    "      return row['col1'] * row['col2']\n",
    "\n",
    "    start_time = time.time()\n",
    "    df.apply(apply_func, axis=1).sum()\n",
    "    end_time = time.time()\n",
    "    print(f\"Apply time: {end_time - start_time:.4f} seconds\")\n",
    "    ```\n",
    "\n",
    "**Practice Exercises:**\n",
    "\n",
    "1.  **Real-World Dataset:**\n",
    "    *   Find a dataset on Kaggle or another data repository (e.g., UCI Machine Learning Repository).\n",
    "    *   Load the data into a Pandas DataFrame.\n",
    "    *   Clean the data:\n",
    "        *   Handle missing values.\n",
    "        *   Convert data types as needed.\n",
    "        *   Perform any necessary string manipulation.\n",
    "    *   Transform the data:\n",
    "        *   Create new features.\n",
    "        *   Apply custom functions.\n",
    "    *   Analyze the data:\n",
    "        *   Use `groupby` to aggregate data.\n",
    "        *   Filter data based on conditions.\n",
    "        *   Merge or join with other DataFrames if applicable.\n",
    "\n",
    "2.  **Time Series Analysis:**\n",
    "    *   Find a dataset with time-based information (e.g., stock prices, weather data).\n",
    "    *   Load the data into a Pandas DataFrame and set the time column as the index.\n",
    "    *   Resample the data to different frequencies (e.g., daily, weekly, monthly).\n",
    "    *   Calculate rolling statistics (e.g., moving averages).\n",
    "    *   Shift the data to create lagged features.\n",
    "\n",
    "3.  **Pivot Tables and Cross-Tabulations:**\n",
    "    *   Using the dataset from Exercise 1 or 2, create pivot tables to summarize the data in different ways.\n",
    "    *   Create cross-tabulations to analyze the relationships between categorical variables.\n",
    "\n",
    "This course provides a strong foundation in advanced Pandas techniques. Remember to practice consistently, explore the Pandas documentation, and adapt these techniques to your specific data analysis tasks. The best way to learn is by doing!\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
