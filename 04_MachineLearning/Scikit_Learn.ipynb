{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning with Scikit-learn\n",
    "\n",
    "**Basic ML Concepts**\n",
    "\n",
    "*   **Supervised vs. Unsupervised Learning:**\n",
    "    *   **Supervised Learning:**  You have labeled data (input features and corresponding output labels).  The goal is to learn a mapping from inputs to outputs.\n",
    "        *   **Regression:** Predict a continuous output variable (e.g., house price, temperature).\n",
    "        *   **Classification:** Predict a categorical output variable (e.g., spam/not spam, image category).\n",
    "    *   **Unsupervised Learning:** You have unlabeled data (only input features).  The goal is to discover patterns or structure in the data.\n",
    "        *   **Clustering:** Group similar data points together (e.g., customer segmentation).\n",
    "        *   **Dimensionality Reduction:** Reduce the number of features while preserving important information (e.g., PCA).\n",
    "\n",
    "*   **Model Evaluation:**\n",
    "    *   **Regression Metrics:**\n",
    "        *   **Mean Squared Error (MSE):** Average squared difference between predicted and actual values.\n",
    "        *   **Root Mean Squared Error (RMSE):** Square root of MSE (more interpretable).\n",
    "        *   **R-squared (Coefficient of Determination):**  Proportion of variance in the output variable explained by the model.\n",
    "    *   **Classification Metrics:**\n",
    "        *   **Accuracy:** Proportion of correctly classified instances.\n",
    "        *   **Precision:**  Proportion of true positives among all predicted positives (how many predicted \"spam\" emails are actually spam?).\n",
    "        *   **Recall:** Proportion of true positives among all actual positives (how many actual spam emails were correctly identified?).\n",
    "        *   **F1-score:** Harmonic mean of precision and recall (balances the two).\n",
    "        *   **ROC Curve (Receiver Operating Characteristic):**  Plots the true positive rate against the false positive rate at various threshold settings.\n",
    "        *   **AUC (Area Under the ROC Curve):**  A single number summarizing the ROC curve (higher is better).\n",
    "    *   **Cross-Validation:**  A technique to evaluate model performance more robustly by splitting the data into multiple folds and training/testing on different combinations of folds.  This helps prevent overfitting to a single training set. Common types:\n",
    "        *   **K-Fold Cross-Validation:** Split data into K folds, train on K-1, test on the remaining fold, repeat K times.\n",
    "        * **Stratified K-Fold:** K-Fold, but ensures class proportions are maintained in each fold (important for imbalanced datasets).\n",
    "        * **Leave-One-Out Cross-Validation (LOOCV):** Extreme case of K-Fold, where K = number of samples.\n",
    "\n",
    "*   **Bias-Variance Tradeoff:**\n",
    "    *   **Bias:**  Error due to overly simplistic assumptions in the model (underfitting).\n",
    "    *   **Variance:**  Error due to sensitivity to fluctuations in the training data (overfitting).\n",
    "    *   **Tradeoff:**  Finding the right balance between bias and variance to achieve good generalization performance.\n",
    "\n",
    "*   **Overfitting and Underfitting:**\n",
    "    *   **Overfitting:**  The model learns the training data too well, including noise and irrelevant details.  Performs poorly on unseen data.\n",
    "    *   **Underfitting:**  The model is too simple to capture the underlying patterns in the data.  Performs poorly on both training and unseen data.\n",
    "\n",
    "**Scikit-learn API**\n",
    "\n",
    "*   **Estimators:**  Objects that learn from data (e.g., `LinearRegression`, `LogisticRegression`, `DecisionTreeClassifier`).  They have a `fit()` method to train the model and a `predict()` method to make predictions.\n",
    "\n",
    "*   **Transformers:** Objects that transform data (e.g., `StandardScaler`, `OneHotEncoder`).  They have a `fit()` method to learn parameters from the data and a `transform()` method to apply the transformation.  `fit_transform()` combines both steps.\n",
    "\n",
    "*   **Pipelines:**  Combine multiple steps (transformers and an estimator) into a single object.  This simplifies the workflow and ensures that the same preprocessing is applied to both training and test data.\n",
    "\n",
    "**Data Preprocessing**\n",
    "\n",
    "*   **Scaling:**  Transform features to a similar range (e.g., 0 to 1 or -1 to 1).  Important for algorithms that are sensitive to feature scales (e.g., SVM, k-NN).\n",
    "\n",
    "    ```python\n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "    import numpy as np\n",
    "\n",
    "    data = np.array([[1, 10], [2, 20], [3, 30]])\n",
    "\n",
    "    # Standard scaling (mean=0, std=1)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    print(\"Standard Scaled:\\n\", scaled_data)\n",
    "\n",
    "    # Min-max scaling (range [0, 1])\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    min_max_scaled_data = min_max_scaler.fit_transform(data)\n",
    "    print(\"MinMax Scaled:\\n\", min_max_scaled_data)\n",
    "    ```\n",
    "\n",
    "*   **Normalization:**  Scale individual samples to have unit norm (useful for text classification or clustering).\n",
    "\n",
    "    ```python\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "\n",
    "    normalizer = Normalizer()\n",
    "    normalized_data = normalizer.fit_transform(data)\n",
    "    print(\"Normalized:\\n\", normalized_data)\n",
    "    ```\n",
    "\n",
    "*   **One-Hot Encoding:**  Convert categorical features into numerical features by creating binary columns for each category.\n",
    "\n",
    "    ```python\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "    data = np.array([['Red'], ['Green'], ['Blue'], ['Red']])\n",
    "\n",
    "    encoder = OneHotEncoder()\n",
    "    encoded_data = encoder.fit_transform(data)  # Returns a sparse matrix\n",
    "    print(\"One-Hot Encoded:\\n\", encoded_data.toarray()) # Convert to dense array for display\n",
    "\n",
    "    #Handle unknown values\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    encoder.fit(data)\n",
    "    new_data = np.array([['Red'], ['Yellow']])\n",
    "    encoded_new_data = encoder.transform(new_data)\n",
    "    print(\"Encoded new data (with unknown handling):\\n\", encoded_new_data.toarray())\n",
    "\n",
    "    ```\n",
    "\n",
    "*   **Feature Engineering:**  Creating new features from existing ones to improve model performance. This often requires domain knowledge. Examples:\n",
    "    *   Polynomial features: Create interaction terms (e.g., x1 * x2).\n",
    "    *   Binning: Convert continuous features into categorical features.\n",
    "    *   Text features: Extract features like word counts, TF-IDF.\n",
    "\n",
    "    ```python\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "    data = np.array([[1, 2], [3, 4]])\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    poly_data = poly.fit_transform(data)\n",
    "    print(\"Polynomial Features:\\n\", poly_data)\n",
    "    ```\n",
    "\n",
    "**Model Training and Evaluation**\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# --- Regression Example (Linear Regression) ---\n",
    "# Generate some sample data\n",
    "X = np.random.rand(100, 1) * 10\n",
    "y = 2 * X + 1 + np.random.randn(100, 1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = model.score(X_test, y_test)  # R-squared\n",
    "\n",
    "print(\"Regression Results:\")\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# --- Classification Example (Logistic Regression) ---\n",
    "# Create a sample dataset for classification\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=200, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"\\nClassification Results (Logistic Regression):\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# --- Other Models (Decision Tree, SVM, k-NN) ---\n",
    "# (Similar workflow - fit, predict, evaluate)\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "print(\"\\nDecision Tree Accuracy:\", accuracy_score(y_test, dt_pred))\n",
    "\n",
    "# SVM\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "print(\"\\nSVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
    "\n",
    "# k-NN\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "print(\"\\nk-NN Accuracy:\", accuracy_score(y_test, knn_pred))\n",
    "```\n",
    "\n",
    "**Model Selection and Hyperparameter Tuning**\n",
    "\n",
    "*   **Grid Search:**  Exhaustively search over a specified parameter grid to find the best combination of hyperparameters.\n",
    "\n",
    "    ```python\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier # Example with a different model\n",
    "\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],  # Number of trees\n",
    "        'max_depth': [None, 10, 20, 30],    # Maximum depth of trees\n",
    "        'min_samples_split': [2, 5, 10]     # Minimum samples required to split a node\n",
    "    }\n",
    "\n",
    "    # Create a Random Forest classifier\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                              cv=3, scoring='accuracy', n_jobs=-1) # Use all available cores\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and best score\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "    # Get the best estimator\n",
    "    best_rf = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the best estimator on the test set\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "    print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
    "    ```\n",
    "\n",
    "*   **Randomized Search:**  Sample a fixed number of parameter settings from specified distributions.  More efficient than grid search when you have many hyperparameters.\n",
    "\n",
    "    ```python\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from scipy.stats import randint  # For integer parameters\n",
    "\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(50, 200),\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': randint(2, 11)\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
    "                                      n_iter=10, cv=3, scoring='accuracy',\n",
    "                                      random_state=42, n_jobs=-1)\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(\"Best Parameters (Randomized Search):\", random_search.best_params_)\n",
    "    ```\n",
    "*   **Cross-Validation with Hyperparameter Tuning:** Grid search and randomized search use cross-validation internally to evaluate different parameter combinations. This ensures that the hyperparameter selection is not biased towards a specific train/test split.\n",
    "\n",
    "**Pipelines**\n",
    "\n",
    "*   **Combine Preprocessing and Model Training:**\n",
    "\n",
    "    ```python\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Step 1: Standard scaling\n",
    "        ('svm', SVC())                # Step 2: SVM classifier\n",
    "    ])\n",
    "\n",
    "    # Fit the pipeline to the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Evaluate the pipeline\n",
    "    print(\"Pipeline Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # Pipeline with GridSearchCV\n",
    "    param_grid = {\n",
    "      'scaler__with_mean': [True, False], # Accessing parameters within the pipeline\n",
    "      'svm__C': [0.1, 1, 10],\n",
    "      'svm__kernel': ['linear', 'rbf']\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best Pipeline Parameters:\", grid_search.best_params_)\n",
    "    ```\n",
    "\n",
    "**Practice:**\n",
    "\n",
    "1.  **Work through Scikit-learn Tutorials:**  The official documentation has excellent tutorials that cover many of these topics.  This is a great way to get hands-on experience.\n",
    "\n",
    "2.  **Apply Different Algorithms:**  Use a real-world dataset (e.g., from Kaggle, UCI Machine Learning Repository, or the datasets included in Scikit-learn) and apply different algorithms (linear regression, logistic regression, decision trees, SVM, k-NN) to the same dataset.  Compare their performance using appropriate metrics.\n",
    "\n",
    "3.  **Implement Cross-Validation:**  Use cross-validation to evaluate the performance of your models more robustly.  Experiment with different cross-validation strategies (k-fold, stratified k-fold).\n",
    "\n",
    "4.  **Hyperparameter Tuning:**  Use grid search or randomized search to tune the hyperparameters of at least one of your models.  Compare the performance of the tuned model to the default model.\n",
    "\n",
    "5.  **Pipelines**: Build a pipeline including scaling, and a classifier. Train and evaluate the pipeline. Experiment with different scalers.\n",
    "\n",
    "This course provides a practical introduction to machine learning with Scikit-learn.  By working through the code examples and practice exercises, you'll gain a solid understanding of the key concepts and techniques needed to start building and evaluating your own machine learning models. Remember to consult the Scikit-learn documentation for more details and advanced features.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
