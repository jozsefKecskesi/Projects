{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Python Fundamentals & Functional Programming**\n",
    "\n",
    "**Metaclasses**\n",
    "\n",
    "*   **What are Metaclasses?** Metaclasses are \"classes of classes.\"  They control the creation of classes, just like classes control the creation of objects.  By default, the metaclass of a class is `type`.\n",
    "\n",
    "*   **How Metaclasses Work:** When you define a class, Python calls the metaclass (usually `type`) to create the class object.  You can create custom metaclasses by inheriting from `type` and overriding its `__new__` method (and optionally `__init__`).\n",
    "\n",
    "*   **Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating class: MyClass\n",
      "Base Classes : ()\n",
      "Atributtes : {'__module__': '__main__', '__qualname__': 'MyClass', 'my_method': <function MyClass.my_method at 0x744cd02f1260>, 'attribute_added_by_metaclass': True}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyMetaclass(type):\n",
    "    def __new__(cls, name, bases, attrs):\n",
    "        # Modify attributes before class creation\n",
    "        attrs['attribute_added_by_metaclass'] = True\n",
    "        print(f\"Creating class: {name}\")\n",
    "        print(f\"Base Classes : {bases}\")\n",
    "        print(f\"Atributtes : {attrs}\")\n",
    "        return super().__new__(cls, name, bases, attrs)\n",
    "\n",
    "class MyClass(metaclass=MyMetaclass):\n",
    "    def my_method(self):\n",
    "        pass\n",
    "\n",
    "obj = MyClass()\n",
    "print(obj.attribute_added_by_metaclass)  # Output: True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    In this example, `MyMetaclass` adds an attribute to `MyClass` during class creation.  The `__new__` method is called *before* the class is created.  It receives the class name, base classes (tuple), and attributes (dictionary).  `super().__new__(...)` calls the base metaclass's `__new__` to actually create the class.\n",
    "\n",
    "*   **Use Cases (Rare in direct AI, but important for understanding frameworks):**\n",
    "    *   Enforcing coding standards (e.g., ensuring all classes have a specific method).\n",
    "    *   Automatically registering classes (e.g., in a plugin system).\n",
    "    *   Modifying class attributes or methods dynamically.\n",
    "    *   Creating framework-level features (ORM's, like in Django, use metaclasses).\n",
    "\n",
    "**Descriptors**\n",
    "\n",
    "*   **What are Descriptors?** Descriptors are a way to control attribute access. They are Python objects that implement the descriptor protocol: `__get__`, `__set__`, and optionally `__delete__`.\n",
    "\n",
    "*   **How Descriptors Work:** When you access an attribute on an object, Python checks if the attribute is a descriptor. If it is, Python calls the descriptor's `__get__` method instead of directly returning the attribute's value. Similarly, `__set__` is called for assignment, and `__delete__` for deletion.\n",
    "\n",
    "*   **Example (Data Descriptor - implements `__set__`):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting value from instance: <__main__.MyClass object at 0x744cd04a75f0>, owner: <class '__main__.MyClass'>\n",
      "10\n",
      "Setting value in instance <__main__.MyClass object at 0x744cd04a75f0> to 20\n",
      "Getting value from instance: None, owner: <class '__main__.MyClass'>\n",
      "<__main__.DataValidator object at 0x744cd04a74a0>\n"
     ]
    }
   ],
   "source": [
    "class DataValidator:\n",
    "    def __init__(self, initial_value=None):\n",
    "        self.value = initial_value\n",
    "\n",
    "    def __get__(self, instance, owner):\n",
    "        print(f\"Getting value from instance: {instance}, owner: {owner}\")\n",
    "        if instance is None:  # Accessed through the class itself\n",
    "            return self\n",
    "        return self.value\n",
    "\n",
    "    def __set__(self, instance, value):\n",
    "        print(f\"Setting value in instance {instance} to {value}\")\n",
    "        if not isinstance(value, int):\n",
    "            raise TypeError(\"Value must be an integer\")\n",
    "        self.value = value\n",
    "\n",
    "class MyClass:\n",
    "    data = DataValidator(10)  # DataValidator instance is the descriptor\n",
    "\n",
    "obj = MyClass()\n",
    "print(obj.data)  # Access: Calls DataValidator.__get__\n",
    "obj.data = 20   # Assignment: Calls DataValidator.__set__\n",
    "# obj.data = \"hello\"  # Raises TypeError\n",
    "\n",
    "print(MyClass.data) #Access through the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **Example (Non-Data Descriptor - only implements `__get__`):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting value: 4 from instance: <__main__.MyClassND object at 0x744cd02f8e00>, owner: <class '__main__.MyClassND'>\n",
      "4\n",
      "8\n",
      "Getting value: 4 from instance: None, owner: <class '__main__.MyClassND'>\n",
      "<__main__.NonDataDescriptor object at 0x744cd02f8b00>\n"
     ]
    }
   ],
   "source": [
    "class NonDataDescriptor:\n",
    "    def __init__(self, initial_value):\n",
    "        self.value = initial_value\n",
    "    def __get__(self, instance, owner):\n",
    "        print(f\"Getting value: {self.value} from instance: {instance}, owner: {owner}\")\n",
    "        if instance is None:\n",
    "            return self\n",
    "        return self.value\n",
    "\n",
    "class MyClassND:\n",
    "    attribute = NonDataDescriptor(4)\n",
    "\n",
    "my_objectND = MyClassND()\n",
    "print(my_objectND.attribute)\n",
    "my_objectND.attribute = 8 # Doesn't call __set__\n",
    "print(my_objectND.attribute) # Doesn't call __get__\n",
    "print(MyClassND.attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **Relationship to Properties and Methods:**  Properties and methods are implemented using descriptors behind the scenes. `property` is a built-in descriptor.\n",
    "\n",
    "**Advanced Decorators**\n",
    "\n",
    "*   **Parameterized Decorators:** Decorators that take arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n",
      "Hello, World!\n",
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "def repeat(num_times):  # Outer function takes arguments\n",
    "    def decorator_repeat(func):  # Inner function is the actual decorator\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for _ in range(num_times):\n",
    "                result = func(*args, **kwargs)\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator_repeat\n",
    "\n",
    "@repeat(num_times=3)  # Apply the parameterized decorator\n",
    "def greet(name):\n",
    "    print(f\"Hello, {name}!\")\n",
    "\n",
    "greet(\"World\")  # Output: Hello, World! (printed 3 times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **Class-Based Decorators:** Decorators implemented as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function slow_function took 2.0001 seconds\n"
     ]
    }
   ],
   "source": [
    "class TimeIt:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        result = self.func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Function {self.func.__name__} took {end_time - start_time:.4f} seconds\")\n",
    "        return result\n",
    "\n",
    "@TimeIt  # Apply the class-based decorator\n",
    "def slow_function(n):\n",
    "    import time\n",
    "    time.sleep(n)\n",
    "\n",
    "slow_function(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The `__call__` method makes the class instance callable, like a function.\n",
    "\n",
    "*   **Use Cases:**\n",
    "    *   **Memoization (Caching):**  Store the results of expensive function calls to avoid redundant computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "CacheInfo(hits=8, misses=11, maxsize=None, currsize=11)\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)  # Built-in memoization decorator\n",
    "def fibonacci(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "print(fibonacci(10))  # Calculates quickly due to caching\n",
    "print(fibonacci.cache_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    *   **Timing Functions:** (See the `TimeIt` example above).\n",
    "    *   **Argument Validation:** Check the types or values of function arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 1, b: hello, c: 3.14\n",
      "a: 1, b: hi, c: None\n"
     ]
    }
   ],
   "source": [
    "def validate_types(**types):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for i, arg in enumerate(args):\n",
    "                expected_type = types.get(func.__code__.co_varnames[i])\n",
    "                if expected_type and not isinstance(arg, expected_type):\n",
    "                    raise TypeError(f\"Argument {func.__code__.co_varnames[i]} must be of type {expected_type.__name__}\")\n",
    "\n",
    "            for key, value in kwargs.items():\n",
    "                expected_type = types.get(key)\n",
    "                if expected_type and not isinstance(value, expected_type):\n",
    "                    raise TypeError(f\"Argument {key} must be of type {expected_type.__name__}\")\n",
    "\n",
    "            return func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@validate_types(a=int, b=str)  # Specify expected types\n",
    "def my_function(a, b, c=None):\n",
    "    print(f\"a: {a}, b: {b}, c: {c}\")\n",
    "\n",
    "my_function(1, \"hello\", c=3.14)\n",
    "# my_function(\"hello\", 1)  # Raises TypeError\n",
    "my_function(1, b = \"hi\")\n",
    "# my_function(1, b = 3) #Raises TypeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generators and Iterators (Advanced)**\n",
    "\n",
    "*   **`yield` Keyword:**  Creates a generator function.  When called, a generator function returns a generator object, which is an iterator.  `yield` pauses the function's execution and returns a value.  The next time the generator's `__next__` method is called, execution resumes from where it left off.\n",
    "\n",
    "*   **Generator Expressions:**  Concise way to create generators, similar to list comprehensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Generator function\n",
    "def even_numbers(max_num):\n",
    "    for n in range(2, max_num + 1, 2):\n",
    "        yield n\n",
    "\n",
    "# Generator expression\n",
    "even_numbers_gen = (n for n in range(2, 11, 2))  # Generates even numbers up to 10\n",
    "\n",
    "for num in even_numbers(10):\n",
    "    print(num)\n",
    "\n",
    "for num in even_numbers_gen:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **Iterator Protocol:**\n",
    "    *   `__iter__`:  Returns the iterator object itself (usually `self`).\n",
    "    *   `__next__`:  Returns the next item in the sequence.  Raises `StopIteration` when there are no more items.\n",
    "\n",
    "*   **Example (Custom Iterator):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "class MyRange:\n",
    "    def __init__(self, start, end):\n",
    "        self.current = start\n",
    "        self.end = end\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current >= self.end:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            value = self.current\n",
    "            self.current += 1\n",
    "            return value\n",
    "\n",
    "for i in MyRange(1, 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **Difference between `__iter__` and `__next__`:**\n",
    "    *   An *iterable* object (like a list) has an `__iter__` method that returns an *iterator*.\n",
    "    *   An *iterator* object has both `__iter__` (which usually just returns itself) and `__next__`.\n",
    "    *   Generators are iterators, and therefore also iterable.\n",
    "\n",
    "* **Use in AI**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'image_paths.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Assume a large dataset of images in 'image_paths.txt'\u001b[39;00m\n\u001b[1;32m     14\u001b[0m image_loader \u001b[38;5;241m=\u001b[39m large_dataset_loader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_paths.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#preproces_images(image_batch) -> Assume this function exists\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#train_model(processed_images) -> Assume this function exists\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing batch of size: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m, in \u001b[0;36mlarge_dataset_loader\u001b[0;34m(filepath, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlarge_dataset_loader\u001b[39m(filepath, batch_size):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m             batch \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image_paths.txt'"
     ]
    }
   ],
   "source": [
    "def large_dataset_loader(filepath, batch_size):\n",
    "    with open(filepath, 'r') as file:\n",
    "        while True:\n",
    "            batch = []\n",
    "            for _ in range(batch_size):\n",
    "                line = file.readline()\n",
    "                if not line:\n",
    "                    if batch:\n",
    "                        yield batch\n",
    "                    return # StopIteration\n",
    "                batch.append(line.strip())\n",
    "            yield batch\n",
    "#Assume a large dataset of images in 'image_paths.txt'\n",
    "image_loader = large_dataset_loader('image_paths.txt', batch_size=32)\n",
    "for image_batch in image_loader:\n",
    "    #preproces_images(image_batch) -> Assume this function exists\n",
    "    #train_model(processed_images) -> Assume this function exists\n",
    "    print(f\"Processing batch of size: {len(image_batch)}\")\n",
    "#The outcome file not found error - no such file in this directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Context Managers**\n",
    "\n",
    "*   **`with` Statement:**  Provides a way to manage resources (like files, locks, network connections) automatically.  Ensures that resources are acquired and released properly, even if exceptions occur.\n",
    "\n",
    "*   **`__enter__` and `__exit__`:**  Methods that define the context management protocol.\n",
    "    *   `__enter__`:  Called when entering the `with` block.  Returns a value that can be assigned to a variable using `as`.\n",
    "    *   `__exit__`:  Called when exiting the `with` block (either normally or due to an exception).  Handles cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'my_file.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example (File Handling):\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_file.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:  \u001b[38;5;66;03m# Automatic file closing\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# File is automatically closed here, even if an error occurred\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_file.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example (File Handling):\n",
    "\n",
    "with open(\"my_file.txt\", \"r\") as f:  # Automatic file closing\n",
    "    data = f.read()\n",
    "# File is automatically closed here, even if an error occurred\n",
    "print(data)\n",
    "\n",
    "# Example (Custom Context Manager):\n",
    "\n",
    "class MyContextManager:\n",
    "    def __init__(self, resource_name):\n",
    "        self.resource_name = resource_name\n",
    "        self.resource = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        print(f\"Acquiring resource: {self.resource_name}\")\n",
    "        self.resource = f\"Resource: {self.resource_name}\"  # Simulate acquiring a resource\n",
    "        return self.resource\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        print(f\"Releasing resource: {self.resource_name}\")\n",
    "        if exc_type:\n",
    "            print(f\"An exception occurred: {exc_type}, {exc_value}\")\n",
    "        # If __exit__ returns True, the exception is suppressed.\n",
    "        # If it returns False (or None), the exception is re-raised.\n",
    "        self.resource = None # Simulate releasing the resource\n",
    "\n",
    "with MyContextManager(\"Database Connection\") as db_connection:\n",
    "    print(f\"Using {db_connection}\")\n",
    "    # raise ValueError(\"Simulated error\") # Uncomment to test exception handling\n",
    "\n",
    "print(\"Outside the context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functional Programming**\n",
    "\n",
    "*   **`map`, `filter`, `reduce`:**\n",
    "    *   `map(function, iterable)`: Applies a function to each item in an iterable and returns an iterator of the results.\n",
    "    *   `filter(function, iterable)`: Filters an iterable, keeping only items for which the function returns `True`.  Returns an iterator.\n",
    "    *   `reduce(function, iterable)`: Applies a function cumulatively to the items of an iterable, reducing it to a single value.  (From `functools` in Python 3).\n",
    "\n",
    "*   **Lambda Functions:** Anonymous functions defined using the `lambda` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n",
      "[2, 4]\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Using map with a lambda function\n",
    "squared_numbers = map(lambda x: x**2, numbers)\n",
    "print(list(squared_numbers))\n",
    "\n",
    "# Using filter with a lambda function\n",
    "even_numbers = filter(lambda x: x % 2 == 0, numbers)\n",
    "print(list(even_numbers))\n",
    "\n",
    "# Using reduce with a lambda function\n",
    "product = reduce(lambda x, y: x * y, numbers)\n",
    "print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **`functools` and `itertools`:**\n",
    "    *   `functools`:  Provides higher-order functions (functions that operate on other functions).  Includes `partial` (create functions with some arguments pre-filled), `lru_cache` (memoization).\n",
    "    *   `itertools`:  Provides functions for creating iterators for efficient looping.  Includes `chain` (combine iterables), `combinations`, `permutations`, `groupby`, and many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "[1, 2, 3, 4, 5, 6]\n",
      "('a', 'b')\n",
      "('a', 'c')\n",
      "('b', 'c')\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# functools.partial\n",
    "def power(base, exponent):\n",
    "    return base ** exponent\n",
    "\n",
    "square = partial(power, exponent=2)  # Create a new function with exponent fixed\n",
    "print(square(5))  # Output: 25\n",
    "\n",
    "# itertools.chain\n",
    "list1 = [1, 2, 3]\n",
    "list2 = [4, 5, 6]\n",
    "combined = chain(list1, list2)\n",
    "print(list(combined))  # Output: [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# itertools.combinations\n",
    "items = ['a', 'b', 'c']\n",
    "for combo in combinations(items, 2):\n",
    "    print(combo)  # Output: ('a', 'b'), ('a', 'c'), ('b', 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concurrency and Parallelism**\n",
    "\n",
    "*   **Threading (`threading` module):**\n",
    "    *   **Global Interpreter Lock (GIL):**  In CPython (the standard Python implementation), the GIL allows only one thread to hold control of the Python interpreter at a time.  This means that threads are not truly parallel for CPU-bound tasks.\n",
    "    *   **Use Cases:** I/O-bound tasks (waiting for network requests, file reads, etc.).  Threads can run concurrently while waiting for I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 0: Starting\n",
      "Thread 1: Starting\n",
      "Thread 2: Starting\n",
      "Thread 0: Finishing\n",
      "Thread 1: Finishing\n",
      "Thread 2: Finishing\n",
      "All threads finished\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def worker(name):\n",
    "    print(f\"Thread {name}: Starting\")\n",
    "    time.sleep(2)  # Simulate I/O operation\n",
    "    print(f\"Thread {name}: Finishing\")\n",
    "\n",
    "threads = []\n",
    "for i in range(3):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "for t in threads:\n",
    "    t.join()  # Wait for threads to finish\n",
    "\n",
    "print(\"All threads finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **Multiprocessing (`multiprocessing` module):**\n",
    "    *   **Bypassing the GIL:**  Creates separate processes, each with its own Python interpreter and memory space.  Achieves true parallelism for CPU-bound tasks.\n",
    "    *   **Processes, Pools, Queues, Shared Memory:**\n",
    "        *   `Process`:  Creates a new process.\n",
    "        *   `Pool`:  A pool of worker processes that can be used to parallelize tasks.\n",
    "        *   `Queue`:  A way for processes to communicate with each other by passing messages.\n",
    "        *   `Value` and `Array`: For sharing simple values or arrays between processes, using shared memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results (using shared Array): [1, 4, 9, 16, 25]\n",
      "Results using Pool [1, 8, 27, 64, 125]\n",
      "Producing 1\n",
      "Producing 2\n",
      "Consuming 1\n",
      "Producing 3\n",
      "Consuming 2\n",
      "Producing 4\n",
      "Producing None\n",
      "Consuming 3\n",
      "Consuming 4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def square(n, results, index):\n",
    "    time.sleep(1) #Simulate workload\n",
    "    results[index] = n * n\n",
    "\n",
    "if __name__ == \"__main__\":  # Important for multiprocessing\n",
    "    numbers = [1, 2, 3, 4, 5]\n",
    "    # Using Array for shared memory. 'i' means integer type\n",
    "    results = multiprocessing.Array('i', len(numbers))\n",
    "\n",
    "    processes = []\n",
    "    for i, num in enumerate(numbers):\n",
    "        p = multiprocessing.Process(target=square, args=(num, results, i))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    print(\"Results (using shared Array):\", list(results))\n",
    "\n",
    "    # --- Using Pool and map ---\n",
    "    def cube(n):\n",
    "        time.sleep(1)\n",
    "        return n*n*n\n",
    "\n",
    "    with multiprocessing.Pool(processes=4) as pool:\n",
    "        cubed_numbers = pool.map(cube, numbers)\n",
    "\n",
    "    print(\"Results using Pool\", cubed_numbers)\n",
    "\n",
    "    # --- Using Queue ---\n",
    "    def producer(queue, data):\n",
    "        for item in data:\n",
    "            print(f\"Producing {item}\")\n",
    "            time.sleep(0.5)\n",
    "            queue.put(item)\n",
    "\n",
    "    def consumer(queue):\n",
    "        while True:\n",
    "            item = queue.get()\n",
    "            if item is None:\n",
    "                break\n",
    "            print(f\"Consuming {item}\")\n",
    "            time.sleep(1)\n",
    "\n",
    "    q = multiprocessing.Queue()\n",
    "    data_to_process = [1,2,3,4, None] #None as sentinel value\n",
    "    p1 = multiprocessing.Process(target=producer, args=(q, data_to_process))\n",
    "    p2 = multiprocessing.Process(target=consumer, args=(q,))\n",
    "\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "\n",
    "    p1.join()\n",
    "    p2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **Asynchronous Programming (`asyncio`):**\n",
    "    *   `async` and `await`:  Keywords for defining and awaiting asynchronous operations.\n",
    "    *   **Event Loop:**  Manages the execution of asynchronous tasks.\n",
    "    *   **Use Cases:**  High-concurrency I/O-bound tasks (e.g., handling many network connections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     22\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 23\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Run the event loop\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal execution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;241m-\u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/asyncio/runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def my_coroutine(name, delay):\n",
    "    print(f\"Coroutine {name}: Starting\")\n",
    "    await asyncio.sleep(delay)  # Simulate an asynchronous I/O operation\n",
    "    print(f\"Coroutine {name}: Finishing\")\n",
    "    return f\"Result from {name}\"\n",
    "\n",
    "async def main():\n",
    "    # Create tasks\n",
    "    task1 = asyncio.create_task(my_coroutine(\"A\", 2))\n",
    "    task2 = asyncio.create_task(my_coroutine(\"B\", 1))\n",
    "\n",
    "    # Run tasks concurrently\n",
    "    results = await asyncio.gather(task1, task2)  # Await multiple tasks\n",
    "    print(results)\n",
    "    print(f\"Main Finishing\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    asyncio.run(main())  # Run the event loop\n",
    "    end_time = time.time()\n",
    "    print(f\"Total execution time: {end_time-start_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This course provides a comprehensive overview of the requested advanced Python topics. Remember that practice is key to mastering these concepts. Work through the examples, modify them, and try applying them to your own projects. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
